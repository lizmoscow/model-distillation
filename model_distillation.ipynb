{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 1e-3\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec87b8491ec4048a2757404cca5fbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=170498071), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset_train = datasets.CIFAR10('data', download=True, train=True, transform=transform)\n",
    "num_train = int(len(dataset_train) * 0.95)\n",
    "dataset_train, dataset_valid = random_split(dataset_train, [num_train, len(dataset_train) - num_train])\n",
    "dataset_test = datasets.CIFAR10('data', download=True, train=False, transform=transform)\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "loader_valid = DataLoader(dataset_valid, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, orig_net, optimizer, criterion, a):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 100\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for idx, (pic, real_label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(pic)\n",
    "        loss = None\n",
    "        if orig_net != None:\n",
    "            label = orig_net(pic)\n",
    "            loss = criterion(predited_label, label, real_label, a)\n",
    "        else:\n",
    "            loss = criterion(predited_label, real_label)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == real_label).sum().item()\n",
    "        total_count += real_label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print('{:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f} | loss {:8.3f} '.format(idx, len(dataloader),\n",
    "                                              total_acc / total_count, total_loss))\n",
    "            total_acc, total_count = 0, 0\n",
    "            total_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (pic, real_label) in enumerate(dataloader):\n",
    "            predited_label = model(pic)\n",
    "            total_acc += (predited_label.argmax(1) == real_label).sum().item()\n",
    "            total_count += real_label.size(0)\n",
    "    return total_acc / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, orig_net, optimizer, criterion, scheduler, a, epochs):\n",
    "    total_accu = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(loader_train, model, orig_net, optimizer, criterion, a)\n",
    "        accu_val = evaluate(loader_valid, model)\n",
    "        if total_accu is not None and total_accu > accu_val:\n",
    "          scheduler.step()\n",
    "        else:\n",
    "           total_accu = accu_val\n",
    "        print('-' * 56)\n",
    "        print('end of epoch {:3d} | valid accuracy {:8.3f} '.format(epoch, accu_val))\n",
    "        print('-' * 56)\n",
    "    print('Checking the results of test dataset.')\n",
    "    accu_test = evaluate(loader_test, model)\n",
    "    print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we train the teacher net. We stop the training early as suggested in the article [\"On the Efficacy of Knowledge Distillation\"](https://arxiv.org/abs/1910.01348)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OriginalNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(8 * 8 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100/  475 batches | accuracy    0.378 | loss  169.454 \n",
      "  200/  475 batches | accuracy    0.483 | loss  141.003 \n",
      "  300/  475 batches | accuracy    0.513 | loss  135.854 \n",
      "  400/  475 batches | accuracy    0.540 | loss  126.297 \n",
      "--------------------------------------------------------\n",
      "end of epoch   1 | valid accuracy    0.613 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.587 | loss  115.748 \n",
      "  200/  475 batches | accuracy    0.595 | loss  113.467 \n",
      "  300/  475 batches | accuracy    0.614 | loss  109.469 \n",
      "  400/  475 batches | accuracy    0.614 | loss  108.578 \n",
      "--------------------------------------------------------\n",
      "end of epoch   2 | valid accuracy    0.668 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.642 | loss  101.397 \n",
      "  200/  475 batches | accuracy    0.648 | loss  101.955 \n",
      "  300/  475 batches | accuracy    0.650 | loss   99.721 \n",
      "  400/  475 batches | accuracy    0.657 | loss   98.224 \n",
      "--------------------------------------------------------\n",
      "end of epoch   3 | valid accuracy    0.692 \n",
      "--------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test accuracy    0.679\n"
     ]
    }
   ],
   "source": [
    "orig_net = OriginalNet()\n",
    "criterion_orig = nn.CrossEntropyLoss()\n",
    "optimizer_orig = torch.optim.Adam(orig_net.parameters(), lr=lr)\n",
    "scheduler_orig = torch.optim.lr_scheduler.StepLR(optimizer_orig, 1.0, gamma=0.1)\n",
    "run(orig_net, None, optimizer_orig, criterion_orig, scheduler_orig, None, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train the student (without the help from the teacher) to see what accuracy it is able to achieve on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Linear(32*16*16, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        x = nn.functional.relu(self.fc1(out))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100/  475 batches | accuracy    0.400 | loss  168.989 \n",
      "  200/  475 batches | accuracy    0.501 | loss  138.641 \n",
      "  300/  475 batches | accuracy    0.536 | loss  129.891 \n",
      "  400/  475 batches | accuracy    0.562 | loss  122.358 \n",
      "--------------------------------------------------------\n",
      "end of epoch   1 | valid accuracy    0.615 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.631 | loss  105.487 \n",
      "  200/  475 batches | accuracy    0.637 | loss  103.243 \n",
      "  300/  475 batches | accuracy    0.649 | loss  100.185 \n",
      "  400/  475 batches | accuracy    0.651 | loss   99.162 \n",
      "--------------------------------------------------------\n",
      "end of epoch   2 | valid accuracy    0.665 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.704 | loss   84.766 \n",
      "  200/  475 batches | accuracy    0.707 | loss   82.677 \n",
      "  300/  475 batches | accuracy    0.705 | loss   83.393 \n",
      "  400/  475 batches | accuracy    0.705 | loss   83.151 \n",
      "--------------------------------------------------------\n",
      "end of epoch   3 | valid accuracy    0.700 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.759 | loss   69.284 \n",
      "  200/  475 batches | accuracy    0.757 | loss   70.155 \n",
      "  300/  475 batches | accuracy    0.751 | loss   70.217 \n",
      "  400/  475 batches | accuracy    0.756 | loss   69.288 \n",
      "--------------------------------------------------------\n",
      "end of epoch   4 | valid accuracy    0.698 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.840 | loss   48.883 \n",
      "  200/  475 batches | accuracy    0.855 | loss   45.187 \n",
      "  300/  475 batches | accuracy    0.854 | loss   45.065 \n",
      "  400/  475 batches | accuracy    0.855 | loss   44.764 \n",
      "--------------------------------------------------------\n",
      "end of epoch   5 | valid accuracy    0.737 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.867 | loss   42.164 \n",
      "  200/  475 batches | accuracy    0.872 | loss   40.747 \n",
      "  300/  475 batches | accuracy    0.869 | loss   41.465 \n",
      "  400/  475 batches | accuracy    0.871 | loss   40.167 \n",
      "--------------------------------------------------------\n",
      "end of epoch   6 | valid accuracy    0.737 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.884 | loss   37.335 \n",
      "  200/  475 batches | accuracy    0.887 | loss   36.837 \n",
      "  300/  475 batches | accuracy    0.886 | loss   37.442 \n",
      "  400/  475 batches | accuracy    0.880 | loss   38.107 \n",
      "--------------------------------------------------------\n",
      "end of epoch   7 | valid accuracy    0.739 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.887 | loss   37.629 \n",
      "  200/  475 batches | accuracy    0.888 | loss   36.734 \n",
      "  300/  475 batches | accuracy    0.890 | loss   35.754 \n",
      "  400/  475 batches | accuracy    0.881 | loss   37.781 \n",
      "--------------------------------------------------------\n",
      "end of epoch   8 | valid accuracy    0.742 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.889 | loss   36.673 \n",
      "  200/  475 batches | accuracy    0.882 | loss   37.125 \n",
      "  300/  475 batches | accuracy    0.888 | loss   36.882 \n",
      "  400/  475 batches | accuracy    0.885 | loss   37.115 \n",
      "--------------------------------------------------------\n",
      "end of epoch   9 | valid accuracy    0.741 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.888 | loss   36.210 \n",
      "  200/  475 batches | accuracy    0.883 | loss   37.157 \n",
      "  300/  475 batches | accuracy    0.888 | loss   36.448 \n",
      "  400/  475 batches | accuracy    0.889 | loss   35.701 \n",
      "--------------------------------------------------------\n",
      "end of epoch  10 | valid accuracy    0.741 \n",
      "--------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test accuracy    0.708\n"
     ]
    }
   ],
   "source": [
    "simple_net = SimpleNet()\n",
    "criterion_simple = nn.CrossEntropyLoss()\n",
    "optimizer_simple = torch.optim.Adam(simple_net.parameters(), lr=lr)\n",
    "scheduler_simple = torch.optim.lr_scheduler.StepLR(optimizer_simple, 1.0, gamma=0.1)\n",
    "run(simple_net, None, optimizer_simple, criterion_simple, scheduler_simple, None, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the student using model distillation technique with the criterion defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(output, bert_prob, real_label, a):\n",
    "    criterion_mse = nn.MSELoss()\n",
    "    criterion_ce = nn.CrossEntropyLoss()\n",
    "    return a * criterion_ce(output, real_label) + (1 - a) * criterion_mse(output, bert_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  100/  475 batches | accuracy    0.408 | loss  181.107 \n",
      "  200/  475 batches | accuracy    0.512 | loss  141.054 \n",
      "  300/  475 batches | accuracy    0.556 | loss  127.399 \n",
      "  400/  475 batches | accuracy    0.577 | loss  120.312 \n",
      "--------------------------------------------------------\n",
      "end of epoch   1 | valid accuracy    0.624 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.639 | loss  103.640 \n",
      "  200/  475 batches | accuracy    0.645 | loss  101.249 \n",
      "  300/  475 batches | accuracy    0.660 | loss   97.025 \n",
      "  400/  475 batches | accuracy    0.659 | loss   97.640 \n",
      "--------------------------------------------------------\n",
      "end of epoch   2 | valid accuracy    0.676 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.709 | loss   86.480 \n",
      "  200/  475 batches | accuracy    0.711 | loss   84.996 \n",
      "  300/  475 batches | accuracy    0.715 | loss   84.199 \n",
      "  400/  475 batches | accuracy    0.716 | loss   83.410 \n",
      "--------------------------------------------------------\n",
      "end of epoch   3 | valid accuracy    0.708 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.761 | loss   74.357 \n",
      "  200/  475 batches | accuracy    0.761 | loss   74.293 \n",
      "  300/  475 batches | accuracy    0.753 | loss   75.112 \n",
      "  400/  475 batches | accuracy    0.756 | loss   74.848 \n",
      "--------------------------------------------------------\n",
      "end of epoch   4 | valid accuracy    0.705 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.826 | loss   60.928 \n",
      "  200/  475 batches | accuracy    0.836 | loss   58.001 \n",
      "  300/  475 batches | accuracy    0.842 | loss   57.196 \n",
      "  400/  475 batches | accuracy    0.838 | loss   57.582 \n",
      "--------------------------------------------------------\n",
      "end of epoch   5 | valid accuracy    0.736 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.851 | loss   56.158 \n",
      "  200/  475 batches | accuracy    0.851 | loss   54.788 \n",
      "  300/  475 batches | accuracy    0.848 | loss   55.337 \n",
      "  400/  475 batches | accuracy    0.856 | loss   54.330 \n",
      "--------------------------------------------------------\n",
      "end of epoch   6 | valid accuracy    0.736 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.864 | loss   53.344 \n",
      "  200/  475 batches | accuracy    0.865 | loss   52.929 \n",
      "  300/  475 batches | accuracy    0.859 | loss   53.499 \n",
      "  400/  475 batches | accuracy    0.860 | loss   54.157 \n",
      "--------------------------------------------------------\n",
      "end of epoch   7 | valid accuracy    0.743 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.871 | loss   51.954 \n",
      "  200/  475 batches | accuracy    0.870 | loss   51.630 \n",
      "  300/  475 batches | accuracy    0.873 | loss   51.540 \n",
      "  400/  475 batches | accuracy    0.869 | loss   52.001 \n",
      "--------------------------------------------------------\n",
      "end of epoch   8 | valid accuracy    0.740 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.881 | loss   50.418 \n",
      "  200/  475 batches | accuracy    0.885 | loss   49.487 \n",
      "  300/  475 batches | accuracy    0.884 | loss   49.313 \n",
      "  400/  475 batches | accuracy    0.882 | loss   49.325 \n",
      "--------------------------------------------------------\n",
      "end of epoch   9 | valid accuracy    0.744 \n",
      "--------------------------------------------------------\n",
      "  100/  475 batches | accuracy    0.881 | loss   50.259 \n",
      "  200/  475 batches | accuracy    0.882 | loss   49.789 \n",
      "  300/  475 batches | accuracy    0.887 | loss   48.450 \n",
      "  400/  475 batches | accuracy    0.886 | loss   48.797 \n",
      "--------------------------------------------------------\n",
      "end of epoch  10 | valid accuracy    0.745 \n",
      "--------------------------------------------------------\n",
      "Checking the results of test dataset.\n",
      "test accuracy    0.717\n"
     ]
    }
   ],
   "source": [
    "simple_net = SimpleNet()\n",
    "optimizer = torch.optim.Adam(simple_net.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "run(simple_net, orig_net, optimizer, criterion, scheduler, 0.9, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have been able to slightly improve the accuracy. I tried to improve on the result by training another model ensembles, however I did not succeed. As I understand this is a common problem that may have many reasons (for me the most difficult one was lack of computational resources (I could not use complex models), but I have also encountered cases where the student model seemed to be too simple to be improved by distillation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
